{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo\n",
        "O objetivo deste projeto é desenvolver uma interface (streamlit) que seja capaz de sumarizar vídeos do YouTube, o modelo em questão será o mT5."
      ],
      "metadata": {
        "id": "gmoaW1YpPzzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "qh4mXCtHRZtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "## Requirements\n",
        "!pip install sentencepiece youtube-transcript-api gradio"
      ],
      "metadata": {
        "id": "QCE1xFITSjtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summize.py"
      ],
      "metadata": {
        "id": "trrGjuwFRcol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "def Summarizer(link, model):\n",
        "\n",
        "  video_id = link.split(\"=\")[1]\n",
        "\n",
        "  try:\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    FinalTranscript = ' '.join([i['text'] for i in transcript])\n",
        "\n",
        "    if model == \"Pegasus\":\n",
        "      checkpoint = \"google/pegasus-large\"\n",
        "    elif model == \"mT5\":\n",
        "      checkpoint = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
        "    elif model == \"BART\":\n",
        "      checkpoint = \"sshleifer/distilbart-cnn-12-6\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "    inputs = tokenizer(FinalTranscript,\n",
        "                    max_length=1024,\n",
        "                    truncation=True,\n",
        "                    return_tensors=\"pt\")\n",
        "\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"])\n",
        "    summary = tokenizer.batch_decode(summary_ids,\n",
        "                                  skip_special_tokens=True,\n",
        "                                  clean_up_tokenization_spaces=False)\n",
        "\n",
        "\n",
        "    return summary[0]\n",
        "  except Exception as e:\n",
        "    return \"TranscriptsDisabled: Transcript is not available \\nTry another video\"\n"
      ],
      "metadata": {
        "id": "kWgEXZyrRbC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## App.py"
      ],
      "metadata": {
        "id": "unIrkb1CTAp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "interface = gr.Interface(fn = Summarizer, inputs=[\"text\", \"text\"], outputs=\"text\")\n",
        "interface.launch(debug=True)"
      ],
      "metadata": {
        "id": "dRd8YTAETCHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}